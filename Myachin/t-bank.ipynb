{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14032332,"sourceType":"datasetVersion","datasetId":8935737}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"8efa7715dbe207a9","cell_type":"code","source":"\n","metadata":{"ExecuteTime":{"end_time":"2025-12-06T18:35:03.172067Z","start_time":"2025-12-06T18:30:31.009225Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"55e43f9e8a464617","cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer\n\n# --- 1. ЗАГРУЗКА ---\nFILE_PATH = '/kaggle/input/train-csv/train.csv'\ndf = pd.read_csv(FILE_PATH)\n\n# Удаляем пустые строки\ndf = df.dropna(subset=['review_text', 'reason', 'business_line'])\n\n# --- 2. ГРУППИРОВКА КЛАССОВ ---\nsynonyms = {\n    \"неверная консультация\": \"консультация\",\n    \"некорректная консультация\": \"консультация\",\n    \"консультация по услуге\": \"консультация\",\n    \"консультация\": \"консультация\",\n    \"блокировка/разблокировка карты\": \"блокировка\",\n    \"ограничение операций\": \"блокировка\",\n    \"запрет операций\": \"блокировка\",\n    \"заблокировать сим-карту/разблокировать сим-карту\": \"блокировка\",\n    \"документы\": \"документы\",\n    \"запрос документов aml\": \"документы\",\n    \"предоставление документов\": \"документы\",\n    \"тарифы\": \"тарифы и условия\",\n    \"тарифы по депозитным продуктам\": \"тарифы и условия\",\n    \"тарификация мобайл\": \"тарифы и условия\",\n    \"акции\": \"акции и бонусы\",\n    \"кэшбэк\": \"акции и бонусы\",\n    \"программы лояльности\": \"акции и бонусы\",\n    \"бонус не начислен\": \"акции и бонусы\",\n    \"долго решали вопрос\": \"качество обслуживания\",\n    \"равнодушие\": \"качество обслуживания\",\n    \"манера общения\": \"качество обслуживания\",\n    \"претензия на работу доп услуг\": \"качество обслуживания\",\n    \"общая информация\": \"другое\",\n    \"другое\": \"другое\"\n}\ndf['reason_clean'] = df['reason'].map(lambda x: synonyms.get(x, x))\n\n# Убираем редкие классы\ncounts = df['reason_clean'].value_counts()\nvalid_classes = counts[counts >= 5].index\ndf = df[df['reason_clean'].isin(valid_classes)]\n\n# --- 3. ИНЖЕНЕРИЯ ПРИЗНАКОВ (ГЛАВНОЕ ИЗМЕНЕНИЕ) ---\n# Мы склеиваем \"business_line\" и \"review_text\"\n# Модель увидит: \"Продукт: кредитка | Отзыв: списали лишние проценты...\"\ndef combine_text(row):\n    product = str(row['business_line']).strip()\n    text = str(row['review_text']).strip()\n    # Используем разделитель \" | \" или спецтокен \"[SEP]\"\n    return f\"Продукт: {product} | Отзыв: {text}\"\n\ndf['combined_text'] = df.apply(combine_text, axis=1)\n\n# Проверим, как это выглядит\nprint(\"Пример входных данных для модели:\")\nprint(df['combined_text'].iloc[0])\nprint(\"-\" * 30)\n\n# --- 4. DATASET ---\nlabels_list = sorted(df['reason_clean'].unique().tolist())\nlabel2id = {l: i for i, l in enumerate(labels_list)}\nid2label = {i: l for i, l in enumerate(labels_list)}\ndf['label'] = df['reason_clean'].map(label2id)\n\ntrain_df, test_df = train_test_split(df, test_size=0.15, stratify=df['label'], random_state=42)\nfrom sklearn.utils import resample\n\n# Функция для балансировки\ndef balance_dataframe(df, label_col='label'):\n    # 1. Находим размер самого большого класса\n    max_size = df[label_col].value_counts().max()\n    \n    lst = [df]\n    for class_index, group in df.groupby(label_col):\n        # Если класс меньше максимума, размножаем его\n        if len(group) < max_size:\n            # Размножаем с возвращением (replace=True)\n            augmented = resample(\n                group, \n                replace=True, \n                n_samples=max_size, \n                random_state=42\n            )\n            lst.append(augmented)\n        else:\n            # Если это и так большой класс, берем как есть (или можно тоже resample, но зачем)\n            # Чтобы не дублировать оригинал, который уже в lst[0], \n            # тут логика чуть сложнее. Проще пересобрать всё заново:\n            pass\n            \n    # ПЕРЕПИСЫВАЕМ ЛОГИКУ ДЛЯ ЧИСТОТЫ:\n    \n    df_balanced = pd.DataFrame()\n    # Проходим по каждому классу\n    for class_index, group in df.groupby(label_col):\n        if len(group) < max_size:\n             # Редкие классы дублируем до max_size\n             group_resampled = resample(group, replace=True, n_samples=max_size, random_state=42)\n        else:\n             # Частые классы берем как есть (можно чуть урезать, если хотите undersampling)\n             group_resampled = group\n             \n        df_balanced = pd.concat([df_balanced, group_resampled])\n        \n    return df_balanced\n\n# --- ПРИМЕНЕНИЕ ---\n# Важно: Балансируем ТОЛЬКО train. Test трогать нельзя!\nprint(\"Размер train до балансировки:\", len(train_df))\ntrain_df_balanced = balance_dataframe(train_df, label_col='label')\nprint(\"Размер train после балансировки:\", len(train_df_balanced))\n\n# Теперь создаем Dataset из сбалансированного фрейма\ntrain_ds = Dataset.from_pandas(train_df_balanced)\n# test_ds оставляем как был!\ntest_ds = Dataset.from_pandas(test_df)\n\n# --- 5. ТОКЕНИЗАЦИЯ ---\nmodel_name = 'BAAI/bge-m3'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndef preprocess(examples):\n    # ВАЖНО: Токенизируем теперь колонку 'combined_text', а не 'review_text'\n    return tokenizer(\n        examples[\"combined_text\"], \n        truncation=True, \n        max_length=280 # Чуть увеличили длину, так как добавили business_line\n    )\n\nencoded_train = train_ds.map(preprocess, batched=True)\nencoded_test = test_ds.map(preprocess, batched=True)","metadata":{"ExecuteTime":{"end_time":"2025-12-06T18:35:23.445567Z","start_time":"2025-12-06T18:35:07.545902Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T09:52:38.748851Z","iopub.execute_input":"2025-12-07T09:52:38.749550Z","iopub.status.idle":"2025-12-07T09:53:05.924462Z","shell.execute_reply.started":"2025-12-07T09:52:38.749517Z","shell.execute_reply":"2025-12-07T09:53:05.923844Z"}},"outputs":[{"name":"stdout","text":"Пример входных данных для модели:\nПродукт: кредит наличными | Отзыв: ужаснвы сервис и решение вопросов. Одни отписки. \n9.02.25 вношу частично досрочно сумму. Сумма ежемесячного платежа меняется с 38670 до 38580 -то есть кто закончил 2 класса школы знает , что это 90 рублей. платить этот платеж новый 16 платежей . Это значит 90*16=1440 рублей стало по идее меньше для платы. НО последний платеж изменился , как его называют \"корректирующий\" с 37189.31 до 38898. опять же 1 класс математика, это значии , что мой последний платеж увеличился на 1708.69! . проблема заключается в том, что при изменении ежемесячного платежа я уменьшаю переплату на 1440 -Казалось бы здоров! Но 17 платеж вырос на 1708,69. а это значит, что экономия которая была в 1440 полностью съедается \"корректирующии\" платежом и я в общей сложность по графику платежей должна 268.69 больше ! Чем было до этого! \nпроблема в том, что в чате меня не слышат. \nфраза \"лишних процентов вы не заплатите , график корректны, у вас снизилась сумма платежа ежемесячного\" . Вопрос если я не плачу лишних процентов, почему я по графику стала банку больше должна не смотря на снижения ежемесячного платежа??? \nэто уже не первая ситуация с изменением графика , но у меня не было скринов. Причастично досрочных платежах сумма в общей сложности либо не менялась, либо скудно. Да вопрос 268 рубоец. Но уже принципе. Почему Т-банк считает , что население даже 1 класс математики не ужасал в школе и не может сложить суммы? На все мои вопросы я так и не получила ответ , сегодня 18.02.25\n------------------------------\nРазмер train до балансировки: 3104\nРазмер train после балансировки: 21296\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/444 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70712b32f6c84c66b69a097fcf8fde7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af7cd5df5ece42fbb935f2acbc41c2ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b80e7bf145df4b298ff82dbbee780f9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"393e0751293e422ab23b51b9eee9511a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/21296 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d026bc7f35494ecc83eb5864aaa91a75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/548 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed62d4a6414b4afba1849bef3e8c89aa"}},"metadata":{}}],"execution_count":2},{"id":"f2e5ae1a9946f07c","cell_type":"code","source":"import torch\nprint(torch.__version__)","metadata":{"ExecuteTime":{"end_time":"2025-12-06T18:35:05.387963Z","start_time":"2025-12-06T18:35:05.384893Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T09:54:50.765633Z","iopub.execute_input":"2025-12-07T09:54:50.765963Z","iopub.status.idle":"2025-12-07T09:54:50.770442Z","shell.execute_reply.started":"2025-12-07T09:54:50.765941Z","shell.execute_reply":"2025-12-07T09:54:50.769803Z"}},"outputs":[{"name":"stdout","text":"2.6.0+cu124\n","output_type":"stream"}],"execution_count":3},{"id":"d88511ec-53a8-4b61-893f-dee54c45ac2a","cell_type":"markdown","source":"","metadata":{}},{"id":"dacb77f2c18bd59a","cell_type":"code","source":"!nvidia-smi","metadata":{"ExecuteTime":{"end_time":"2025-12-06T18:27:54.568815Z","start_time":"2025-12-06T18:27:54.468912Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T08:45:49.853123Z","iopub.execute_input":"2025-12-07T08:45:49.853416Z","iopub.status.idle":"2025-12-07T08:45:50.065494Z","shell.execute_reply.started":"2025-12-07T08:45:49.853399Z","shell.execute_reply":"2025-12-07T08:45:50.064578Z"}},"outputs":[{"name":"stdout","text":"Sun Dec  7 08:45:49 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   37C    P0             25W /  250W |       0MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":4},{"id":"42c87802-7ce5-4ef4-a2bf-2943f5cf3568","cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.utils.class_weight import compute_class_weight\n\n# Предположим, у вас есть список меток из вашего train dataset\n# y_train = [0, 1, 0, 0, 0, 1, 2, ...] \n\n# Вычисляем веса\nclass_weights = compute_class_weight(\n    class_weight=\"balanced\",\n    classes=np.unique(y_train),\n    y=y_train\n)\n\n# Конвертируем в тензор и (важно!) указываем тип float32\nclass_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e86d099f-8442-4c4d-86c5-f6b99dfdb2ce","cell_type":"code","source":"from transformers import Trainer\nfrom torch import nn\n\nclass WeightedTrainer(Trainer):\n    def __init__(self, class_weights, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        # Мы передаем веса при инициализации\n        self.class_weights = class_weights\n    \n    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n        \"\"\"\n        Переопределяем расчет loss, добавляя веса классов.\n        \"\"\"\n        labels = inputs.get(\"labels\")\n        \n        # Прогоняем данные через модель\n        outputs = model(**inputs)\n        logits = outputs.get(\"logits\")\n        \n        # ВАЖНО: Переносим веса на то же устройство (GPU/CPU), где находится модель\n        if self.class_weights is not None:\n            weights = self.class_weights.to(model.device)\n        else:\n            weights = None\n            \n        # Создаем функцию потерь с весами\n        loss_fct = nn.CrossEntropyLoss(weight=weights)\n        \n        # Считаем loss\n        # view(-1, self.model.config.num_labels) нужен, если размерности не совпадают,\n        # но для классификации обычно достаточно (logits, labels)\n        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n        \n        return (loss, outputs) if return_outputs else loss","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7011d00460f05b85","cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\nfrom sklearn.metrics import f1_score, accuracy_score\nimport torch\n\n# Инициализация модели\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    num_labels=len(labels_list),\n    id2label=id2label,\n    label2id=label2id\n)\n\n# Функция метрик\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=1)\n    return {\n        \"accuracy\": accuracy_score(labels, predictions),\n        \"f1_weighted\": f1_score(labels, predictions, average=\"weighted\")\n    }\n\n# Параметры обучения\nargs = TrainingArguments(\n    output_dir=\"/kaggle/working/bank_model_results\", # Папка внутри Kaggle\n    learning_rate=2e-5,\n    per_device_train_batch_size=8, # T4 должна потянуть 8 или 16\n    per_device_eval_batch_size=16,\n    num_train_epochs=4,            # Даем модели время подумать\n    weight_decay=0.01,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1_weighted\",\n    fp16=True,                     # Включаем ускорение GPU\n    report_to=\"none\"               # Отключаем WandB, чтобы не просил логин\n)\n\ntrainer = WeightedTrainer(\n    class_weights=class_weights_tensor,\n    model=model,\n    args=args,\n    train_dataset=encoded_train,\n    eval_dataset=encoded_test,\n    tokenizer=tokenizer,\n    data_collator=DataCollatorWithPadding(tokenizer),\n    compute_metrics=compute_metrics,\n)\n\nprint(\"Запуск обучения на GPU...\")\ntrainer.train()","metadata":{"ExecuteTime":{"end_time":"2025-12-06T18:35:28.048453Z","start_time":"2025-12-06T18:35:27.946219Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T08:45:50.067591Z","iopub.execute_input":"2025-12-07T08:45:50.067867Z"}},"outputs":[{"name":"stderr","text":"2025-12-07 08:45:53.063168: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765097153.258799      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765097153.315663      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ff235c89b3b427c9026f0c198d00126"}},"metadata":{}},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipykernel_47/2563911152.py:38: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0da977bdcdb04124b6eb9d0cf2915743"}},"metadata":{}},{"name":"stdout","text":"Запуск обучения на GPU...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='9007' max='10648' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 9007/10648 54:09 < 09:52, 2.77 it/s, Epoch 3.38/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1 Weighted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.575900</td>\n      <td>3.508874</td>\n      <td>0.087591</td>\n      <td>0.061818</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.942400</td>\n      <td>3.076965</td>\n      <td>0.264599</td>\n      <td>0.250805</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.324500</td>\n      <td>3.237145</td>\n      <td>0.324818</td>\n      <td>0.297129</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"id":"5e0fec1c44da8539","cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Получаем предсказания на тесте\npreds = trainer.predict(encoded_test)\ny_pred = np.argmax(preds.predictions, axis=1)\ny_true = preds.label_ids\n\n# Переводим числа обратно в текст\ny_pred_labels = [id2label[i] for i in y_pred]\ny_true_labels = [id2label[i] for i in y_true]\n\nprint(\"\\n--- ИТОГОВЫЙ ОТЧЕТ ---\")\n# Выводим только классы, которые есть в тесте, чтобы избежать warnings\nunique_labels = sorted(list(set(y_true_labels)))\nprint(classification_report(y_true_labels, y_pred_labels, labels=unique_labels))\n\n# Сохраняем готовую модель\nsave_path = \"/kaggle/working/final_model\"\ntrainer.save_model(save_path)\ntokenizer.save_pretrained(save_path)\nprint(f\"Модель сохранена в {save_path}. Вы можете скачать её в разделе Output справа.\")","metadata":{"ExecuteTime":{"end_time":"2025-12-06T18:38:24.752148Z","start_time":"2025-12-06T18:38:24.748989Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"83465315ca1c48b6","cell_type":"code","source":"\nimport shutil\nshutil.make_archive(\"/kaggle/working/my_bank_model\", 'zip', \"/kaggle/working/final_model\")\nprint(\"Архив создан! Скачайте my_bank_model.zip из панели Output.\")","metadata":{"ExecuteTime":{"end_time":"2025-12-06T18:38:25.645331Z","start_time":"2025-12-06T18:38:25.563160Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"a566fbc96a519f09","cell_type":"code","source":"","metadata":{"ExecuteTime":{"end_time":"2025-12-06T18:38:27.891454Z","start_time":"2025-12-06T18:38:27.886569Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"7e06b178834aacd5","cell_type":"code","source":"\n","metadata":{"ExecuteTime":{"end_time":"2025-12-06T18:38:29.932936Z","start_time":"2025-12-06T18:38:29.924606Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"82c794b74e5e99cd","cell_type":"code","source":"\n","metadata":{"ExecuteTime":{"end_time":"2025-12-06T18:38:30.508439Z","start_time":"2025-12-06T18:38:30.460032Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"3a5ad9b43f56795e","cell_type":"code","source":"","metadata":{"ExecuteTime":{"end_time":"2025-12-06T18:38:37.239833Z","start_time":"2025-12-06T18:38:31.623036Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"79cb052914bd4883","cell_type":"code","source":"","metadata":{"ExecuteTime":{"end_time":"2025-12-06T18:38:39.040702Z","start_time":"2025-12-06T18:38:39.018105Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"c98178d96d1bfc77","cell_type":"code","source":"","metadata":{"ExecuteTime":{"end_time":"2025-12-06T18:08:10.209746Z","start_time":"2025-12-06T18:06:32.996443Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"7a72d93da64a7941","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1a52c9247bbf90da","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}